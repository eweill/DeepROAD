{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!sudo unlink /usr/local/cuda\n",
    "!sudo ln -s /usr/local/cuda-7.5 /usr/local/cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CORES = 6\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    inter_op_parallelism_threads = NUM_CORES,\n",
    "    intra_op_parallelism_threads = NUM_CORES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the placeholders. Note that we include names for more informative errors\n",
    "# and shapes as tensorflow will do static size checking\n",
    "x = tf.placeholder(tf.float32, shape=(1, 10), name='x')\n",
    "W = tf.placeholder(tf.float32, shape=(10, 4), name='W')\n",
    "b = tf.placeholder(tf.float32, shape=(1,  4), name='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The fan-in to the summing junction and the summing operation\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The activation function\n",
    "a = tf.nn.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a softmax filter\n",
    "m = tf.nn.softmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25243405  0.24619542  0.25511307  0.24625748]]\n"
     ]
    }
   ],
   "source": [
    "# The activation function doesn't really change here\n",
    "with tf.Session(config=config) as s:\n",
    "    s.run(tf.initialize_all_variables())\n",
    "    \n",
    "    # Let's create some numpy matrices.\n",
    "    # This is for a single lyaer of four neurons\n",
    "    W_in = np.random.rand(10, 4)\n",
    "    x_in = np.random.rand(1, 10)\n",
    "    b_in = np.random.rand(1,  4)\n",
    "    \n",
    "    val = s.run(m,\n",
    "        feed_dict={\n",
    "            x: x_in,\n",
    "            W: W_in,\n",
    "            b: b_in\n",
    "        })\n",
    "    \n",
    "    print val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
